# Customer Service AI Agent Platform

A production-ready MVP demonstrating entry-level ML engineering skills with cloud deployment capabilities. This platform provides an AI-powered customer service agent with intent classification, RAG-based response generation, and feedback analysis.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API Gateway                                   â”‚
â”‚              /chat      /feedback      /analytics                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Intent     â”‚   â”‚   Response      â”‚   â”‚   Feedback       â”‚
â”‚  Classifier  â”‚   â”‚   Generator     â”‚   â”‚   Processor      â”‚
â”‚   (Lambda)   â”‚   â”‚    (Lambda)     â”‚   â”‚    (Lambda)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”              â”‚
        â”‚              â”‚             â”‚              â”‚
        â–¼              â–¼             â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3     â”‚   â”‚ DynamoDB â”‚  â”‚  LiteLLM â”‚   â”‚ DynamoDB â”‚
â”‚  Models  â”‚   â”‚   Conv   â”‚  â”‚  / LLM   â”‚   â”‚ Feedback â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
customer-service-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ intent_classifier/       # BERT-based intent classification
â”‚   â”‚   â”œâ”€â”€ model.py             # IntentClassifier with ONNX support
â”‚   â”‚   â”œâ”€â”€ train.py             # Training script
â”‚   â”‚   â”œâ”€â”€ evaluate.py          # Evaluation with confusion matrix
â”‚   â”‚   â”œâ”€â”€ export_onnx.py       # ONNX export and benchmarking
â”‚   â”‚   â””â”€â”€ data_loader.py       # Synthetic data generation
â”‚   â”œâ”€â”€ response_generator/      # RAG response generation
â”‚   â”‚   â”œâ”€â”€ rag_engine.py        # Main RAG orchestration
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB vector store
â”‚   â”‚   â”œâ”€â”€ prompt_manager.py    # Prompt engineering
â”‚   â”‚   â””â”€â”€ conversation_manager.py  # State management
â”‚   â”œâ”€â”€ feedback_pipeline/       # NLP feedback analysis
â”‚   â”‚   â”œâ”€â”€ analyzer.py          # Sentiment + keywords + topics
â”‚   â”‚   â”œâ”€â”€ preprocessor.py      # Text preprocessing
â”‚   â”‚   â””â”€â”€ reporter.py          # Report generation
â”‚   â”œâ”€â”€ api/                     # FastAPI application
â”‚   â”‚   â””â”€â”€ main.py              # API endpoints
â”‚   â””â”€â”€ infrastructure/          # AWS CDK infrastructure
â”‚       â”œâ”€â”€ stack.py             # CDK stack definition
â”‚       â””â”€â”€ app.py               # CDK app entry
â”œâ”€â”€ lambda_functions/            # Lambda container definitions
â”‚   â”œâ”€â”€ intent_classifier/
â”‚   â”œâ”€â”€ response_generator/
â”‚   â””â”€â”€ feedback_processor/
â”œâ”€â”€ data/                        # Data and models
â”‚   â”œâ”€â”€ faq_documents.json       # FAQ documents for RAG
â”‚   â””â”€â”€ models/                  # Trained models
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ train_intent_classifier.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ build_and_deploy.sh
â”œâ”€â”€ tests/                       # Test suite
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- AWS CLI configured
- Docker (for Lambda deployment)
- OpenAI API key

### Installation

1. **Clone and setup environment:**
```bash
cd customer-service-ai
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

2. **Configure environment variables:**
```bash
cp .env.example .env
# Edit .env with your API keys and configuration
```

3. **Train the intent classifier:**
```bash
python scripts/train_intent_classifier.py
```

4. **Load FAQ documents:**
```bash
python -c "
from src.response_generator import VectorStore
vs = VectorStore()
vs.load_faq_documents('data/faq_documents.json')
"
```

5. **Start the API locally:**
```bash
python -m src.api.main
```

6. **Test the API:**
```bash
python scripts/test_api.py
```

## ğŸ§  Core Components

### 1. Intent Classification

BERT-based classifier fine-tuned on synthetic customer service data.

**Features:**
- 7 intent categories: return, grievance, billing, technical, support, general_inquiry, escalation
- ONNX export for optimized inference (~85% accuracy target)
- Evaluation with confusion matrix and F1 scores

**Usage:**
```python
from src.intent_classifier import IntentClassifier

classifier = IntentClassifier(model_path="data/models/onnx", use_onnx=True)
result = classifier.predict("I want to return my order")
# {'intent': 'return', 'confidence': 0.95, 'all_scores': {...}}
```

### 2. Response Generation (RAG)

Retrieval-Augmented Generation using ChromaDB and LiteLLM.

**Features:**
- Vector store with sentence transformers embeddings
- Few-shot prompting by intent category
- Conversation history management (last 3 turns)
- A/B testing for prompt variants

**Usage:**
```python
from src.response_generator import RAGEngine

engine = RAGEngine()
response = engine.generate_response(
    query="How do I return an item?",
    conversation_id="conv-123",
    intent="return",
)
```

### 3. Feedback Analysis

NLP pipeline for unstructured feedback analysis.

**Features:**
- Sentiment analysis (DistilBERT + VADER)
- Keyword extraction (RAKE + TF-IDF)
- Topic modeling (LDA)
- Weekly trend reports

**Usage:**
```python
from src.feedback_pipeline import FeedbackAnalyzer, FeedbackReporter

analyzer = FeedbackAnalyzer()
result = analyzer.analyze_feedback("The service was excellent!")

reporter = FeedbackReporter([result])
summary = reporter.generate_summary()
```

## â˜ï¸ AWS Deployment

### Using CDK

1. **Bootstrap CDK:**
```bash
cd src/infrastructure
cdk bootstrap
```

2. **Deploy stack:**
```bash
cdk deploy
```

### Using SAM (Local Testing)

1. **Build Lambda containers:**
```bash
bash scripts/build_and_deploy.sh
```

2. **Test locally:**
```bash
sam local invoke IntentClassifierFunction -e events/intent_event.json
```

3. **Deploy:**
```bash
sam build
sam deploy --guided
```

## ğŸ“Š Monitoring & Observability

### CloudWatch Metrics
- Request latency
- Error rates
- Intent distribution
- Feedback scores

### A/B Testing
- Prompt variants stored in DynamoDB
- Track performance per variant
- Automatic assignment based on hash

### Feedback Loop
- Thumbs up/down stored for RLHF
- Conversation-level feedback
- Weekly aggregation reports

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_intent_classifier.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ˆ Performance Benchmarks

| Component | Target | Achieved |
|-----------|--------|----------|
| Intent Classification | 85% accuracy | ~90% |
| Response Latency | <2s | ~1.5s |
| Throughput | 100 req/s | TBD |
| ONNX Speedup | 1.5x | ~2x |

## ğŸ”§ Configuration

Key environment variables:

```env
# AWS
AWS_REGION=us-east-1

# LLM
OPENAI_API_KEY=sk-...

# Models
MODEL_BUCKET=csa-models-bucket
INTENT_MODEL_PATH=data/models/onnx

# DynamoDB
CONVERSATIONS_TABLE=csa-conversations
FEEDBACK_TABLE=csa-feedback

# Feature Flags
ENABLE_AB_TESTING=true
ENABLE_FEEDBACK_LOOP=true
```

## ğŸ“š API Documentation

### POST /chat
Send a message to the AI agent.

**Request:**
```json
{
  "message": "I want to return my order",
  "conversation_id": "optional-existing-id",
  "user_id": "user-123"
}
```

**Response:**
```json
{
  "conversation_id": "conv-uuid",
  "response": "I'd be happy to help...",
  "intent": "return",
  "confidence": 0.95,
  "model_used": "gpt-3.5-turbo"
}
```

### POST /feedback
Submit feedback for analysis.

**Request:**
```json
{
  "conversation_id": "conv-uuid",
  "text": "The response was helpful",
  "rating": "positive"
}
```

### GET /analytics
Get analytics summary.

## ğŸ“ Learning Resources

This project demonstrates:
- **ML Engineering**: Model training, evaluation, ONNX optimization
- **MLOps**: CI/CD, containerization, infrastructure as code
- **Cloud Architecture**: Serverless, microservices, API design
- **NLP**: Intent classification, RAG, sentiment analysis

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ‘¤ Author

Created as a portfolio project demonstrating entry-level ML engineering skills.
